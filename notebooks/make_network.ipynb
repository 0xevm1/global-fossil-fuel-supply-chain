{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging, sys, pickle\n",
    "import networkx as nx\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(all_data_dirs['pipelines-N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "        all_data_dirs = {\n",
    "            'cities-N':              os.path.join(os.getcwd(),'..','results_backup','output','cities_nodes_dataframe.csv'),\n",
    "            'pipelines-cities':      os.path.join(os.getcwd(),'..','results_backup','output','cities_pipelines_edge_dataframe.csv'),\n",
    "            'ports-cities':          os.path.join(os.getcwd(),'..','results_backup','output','cities_ports_edge_dataframe.csv'),\n",
    "            'railways-cities':       os.path.join(os.getcwd(),'..','results_backup','output','cities_railways_edge_dataframe.csv'),\n",
    "            'coalmines-railways':    os.path.join(os.getcwd(),'..','results_backup','output','coal_mine_railway_edge_dataframe.csv'),\n",
    "            'coalmines-N':           os.path.join(os.getcwd(),'..','results_backup','output','coal_mines_nodes_dataframe.csv'),\n",
    "            'lng-N':                 os.path.join(os.getcwd(),'..','results_backup','output','lng_nodes_dataframe.csv',  ),\n",
    "            'lng-pipelines':         os.path.join(os.getcwd(),'..','results_backup','output','lng_pipeline_edge_dataframe.csv'),\n",
    "            'lng-shipping':          os.path.join(os.getcwd(),'..','results_backup','output','lng_shipping_route_edge_dataframe.csv'),\n",
    "            'oilfields-pipelines':   os.path.join(os.getcwd(),'..','results_backup','output','oil_field_edge_dataframe.csv'),\n",
    "            'oilfields-N':           os.path.join(os.getcwd(),'..','results_backup','output','oil_field_nodes_dataframe.csv'),\n",
    "            'pipelines-pipelines':   os.path.join(os.getcwd(),'..','results_backup','simplify','pipeline_edge_dataframe.csv'),\n",
    "            'pipelines-N':           os.path.join(os.getcwd(),'..','results_backup','output','pipeline_node_dataframe.csv'),\n",
    "            'ports-N':               os.path.join(os.getcwd(),'..','results_backup','output','port_node_dataframe.csv',  ),\n",
    "            'ports-pipelines':       os.path.join(os.getcwd(),'..','results_backup','output','port_pipeline_edge_dataframe.csv'),\n",
    "            'ports-shipping':        os.path.join(os.getcwd(),'..','results_backup','output','port_ship_edge_dataframe.csv'),\n",
    "            'powerstn-N':            os.path.join(os.getcwd(),'..','results_backup','output','power_station_nodes_dataframe.csv'),\n",
    "            'powerstn-pipelines':    os.path.join(os.getcwd(),'..','results_backup','output','power_station_pipeline_edge_dataframe.csv'),\n",
    "            'powerstn-railways':     os.path.join(os.getcwd(),'..','results_backup','output','power_station_railway_edge_dataframe.csv'),\n",
    "            'procplant-N':           os.path.join(os.getcwd(),'..','results_backup','output','processing_plant_nodes_dataframe.csv'),\n",
    "            'procplant-pipelines':   os.path.join(os.getcwd(),'..','results_backup','output','processing_plant_pipeline_edge_dataframe.csv'),\n",
    "            'railways-railways':     os.path.join(os.getcwd(),'..','results_backup','simplify','railway_edge_dataframe.csv'),\n",
    "            'railways-N':            os.path.join(os.getcwd(),'..','results_backup','output','railway_nodes_dataframe.csv'),\n",
    "            'refineries-N':          os.path.join(os.getcwd(),'..','results_backup','output','refinery_nodes_dataframe.csv'),\n",
    "            'refineries-pipelines':  os.path.join(os.getcwd(),'..','results_backup','output','refinery_pipeline_edge_dataframe.csv'),\n",
    "            'shipping-shipping':     os.path.join(os.getcwd(),'..','results_backup','output','shipping_edge_dataframe.csv'),\n",
    "            'shipping-N':            os.path.join(os.getcwd(),'..','results_backup','output','shipping_node_dataframe.csv'),\n",
    "            'wellpads-N':            os.path.join(os.getcwd(),'..','results_backup','output','well_pad_nodes_dataframe.csv'),\n",
    "            'wellpads-pipelines':    os.path.join(os.getcwd(),'..','results_backup','output','well_pad_pipeline_edge_dataframe.csv'),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = [\n",
    "        {'name':'wellpads-pipelines',       'reverse':False,    'dup_1':False, 'dup_2':False,   'desc':'add wellpads -> pipelines'},\n",
    "        {'name':'oilfields-pipelines',      'reverse':False,    'dup_1':False, 'dup_2':False,   'desc':'add fields -> pipelines'},\n",
    "        {'name':'pipelines-pipelines',      'reverse':False,    'dup_1':False, 'dup_2':False,   'desc':'add pipelines -> pipelines'},\n",
    "        {'name':'pipelines-pipelines',      'reverse':True,     'dup_1':False, 'dup_2':False,   'desc':'add pipelines <- pipelines'},\n",
    "        {'name':'ports-pipelines',          'reverse':False,    'dup_1':False, 'dup_2':False,   'desc':'add pipelines -> ports'},\n",
    "        {'name':'ports-pipelines',          'reverse':True,     'dup_1':False, 'dup_2':False,   'desc':'add pipelines <- ports'},\n",
    "        {'name':'ports-shipping',           'reverse':False,    'dup_1':False, 'dup_2':False,   'desc':'add ports -> shipping_lanes'},\n",
    "        {'name':'ports-shipping',           'reverse':True,     'dup_1':False, 'dup_2':False,   'desc':'add ports <- shipping_lanes'},\n",
    "        {'name':'shipping-shipping',        'reverse':False,    'dup_1':False, 'dup_2':False,   'desc':'add shipping_lanes -> shipping_lanes'},\n",
    "        {'name':'shipping-shipping',        'reverse':True,     'dup_1':False, 'dup_2':False,   'desc':'add shipping_lanes <- shipping_lanes'},\n",
    "        {'name':'refineries-pipelines',     'reverse':True,     'dup_1':False, 'dup_2':False,   'desc':'add pipelines -> refineries'},\n",
    "        {'name':'refineries-pipelines',     'reverse':False,    'dup_1':False, 'dup_2':True,    'desc':'add refineries -> pipelines_2'},\n",
    "        {'name':'ports-pipelines',          'reverse':True,     'dup_1':True,  'dup_2':True,    'desc':'add pipelines_2 -> ports_2 '},\n",
    "        {'name':'ports-pipelines',          'reverse':False,    'dup_1':True,  'dup_2':True,    'desc':'add pipelines_2 <- ports_2 '},\n",
    "        {'name':'ports-shipping',           'reverse':False,    'dup_1':True,  'dup_2':True,    'desc':'add ports_2 -> shipping_lanes_2'},\n",
    "        {'name':'ports-shipping',           'reverse':True,     'dup_1':True,  'dup_2':True,    'desc':'add ports_2 <- shipping_lanes_2'},\n",
    "        {'name':'shipping-shipping',        'reverse':False,    'dup_1':True,  'dup_2':True,    'desc':'add shipping_lanes_2 -> shipping_lanes_2'},\n",
    "        {'name':'shipping-shipping',        'reverse':True,     'dup_1':True,  'dup_2':True,    'desc':'add shipping_lanes_2 <- shipping_lanes_2'},\n",
    "        {'name':'pipelines-cities',         'reverse':False,    'dup_1':True, 'dup_2':False,    'desc':'add pipelines_2 -> cities'},\n",
    "        {'name':'powerstn-pipelines',       'reverse':True,     'dup_1':False, 'dup_2':True,    'desc':'add pipelines_2 -> power_stn'},\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipelines-cities\n",
      "ports-shipping\n",
      "pipelines-pipelines\n",
      "ports-pipelines\n",
      "shipping-shipping\n",
      "wellpads-pipelines\n",
      "refineries-pipelines\n",
      "powerstn-pipelines\n",
      "oilfields-pipelines\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "datasets = list(set([step['name'] for step in recipe]))\n",
    "for ds in datasets:\n",
    "    print (ds)\n",
    "    dfs[ds] = pd.read_csv(all_data_dirs[ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['ports-pipelines']['impedance'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_steps = [    \n",
    "    {'name':'pipelines-pipelines',      'reverse':False,    'dup_1':True,  'dup_2':True,    'desc':'add pipelines_2 -> pipelines_2'},\n",
    "    {'name':'pipelines-pipelines',      'reverse':True,     'dup_1':True,  'dup_2':True,    'desc':'add pipelines_2 <- pipelines_2'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:doing step add pipelines_2 -> pipelines_2...\n",
      "pipelines-pipelines ['StartNodeId:START_ID(PipelineNode)', 'EndNodeId:END_ID(PipelineNode)']\n",
      "INFO:__main__:doing step add pipelines_2 <- pipelines_2...\n",
      "pipelines-pipelines ['EndNodeId:END_ID(PipelineNode)', 'StartNodeId:START_ID(PipelineNode)']\n"
     ]
    }
   ],
   "source": [
    "for step in add_steps:\n",
    "            logger.info(f'doing step {step[\"desc\"]}...')\n",
    "            dup_strs = ['','']\n",
    "            start_col = [cc for cc in dfs[step['name']].columns if 'START_ID' in cc][0]\n",
    "            end_col = [cc for cc in dfs[step['name']].columns if 'END_ID' in cc][0]\n",
    "            order = [start_col,end_col]\n",
    "            if step['dup_1']:\n",
    "                dup_strs[0]='_B'\n",
    "            if step['dup_2']:\n",
    "                dup_strs[1]='_B'\n",
    "            if step['reverse']:\n",
    "                order.reverse()\n",
    "                dup_strs.reverse()\n",
    "            print (step['name'],order)\n",
    "\n",
    "            G.add_edges_from([(r[0]+dup_strs[0],r[1]+dup_strs[1],{'z':r[2]}) for r in dfs[step['name']].loc[:,order+['impedance']].values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8996809"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48427013"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 8996809\n",
      "Number of edges: 48427013\n",
      "Average in degree:   5.3827\n",
      "Average out degree:   5.3827\n"
     ]
    }
   ],
   "source": [
    "print (nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
